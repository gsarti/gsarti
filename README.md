<p align="center">
  <a href="https://gsarti.com"><img alt="Portfolio" title="Portfolio" src="https://tinyurl.com/gsarti-shield"></a>
  <a href="https://huggingface.co/gsarti"><img alt="Huggingface Hub" title="Huggingface Hub" src="https://tinyurl.com/hf-shield"></a>
  <!--<a href="https://research.rug.nl/en/persons/gabriele-sarti"><img alt="RUG Pure Profile" title="RUG Pure Profile" src="https://tinyurl.com/rug-pure-shield"></a>-->
  <a href="https://twitter.com/gsarti_"><img alt="Twitter" title="Twitter" src="https://img.shields.io/badge/profile-000000?style=for-the-badge&logo=x&logoColor=white"/></a>
  <a href="https://www.linkedin.com/in/gabrielesarti/"><img alt="LinkedIn" title="LinkedIn"src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white"></a>
  <a href="https://scholar.google.it/citations?user=sK0B_08AAAAJ&hl=en"><img alt="Google Scholar" title="Google Scholar"src="https://img.shields.io/badge/scholar-77a9fa.svg?&style=for-the-badge&logo=google-scholar&logoColor=white"></a>
</p>

<a href="https://github.com/404"><img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif"></a>

I am a postdoc at the [BauLab](https://baulab.info/) in Northeastern University, as part of the NSF [National Deep Inference Fabric (NDIF)](https://ndif.us) project. Previously, I was a PhD student at the University of Groningen [GroNLP Lab](https://www.rug.nl/research/clcg/research/cl/) and part of the Dutch [InDeep consortium](https://projects.illc.uva.nl/indeep/), where I wrote a thesis on [actionable interpretability for machine translation](https://gsarti.com/phd-thesis/). Before that, I was also an applied scientist intern at [AWS AI Labs](https://aws.amazon.com/translate/) NYC, a research scientist at [Aindo](https://www.aindo.com) and a founding member of the [AI Student Society](https://www.ai2s.it) in Trieste.

My research aims to bridge the gap between advances in interpretability research on large language models (LLMs) and their downstream applications for improving the transparency and trustworthiness of such models. I am also very passionate about open-source collaboration :octocat:, and I believe that good tools play a fundamental role in scientific discovery. For this reason, I participate in the development of NDIF's [nnsight](https://nnsight.net) interpretability toolkit, and lead the development of [inseq](https://github.com/inseq-team/inseq) for attributional analyses of generative language models.
